"""
Gemini API å¯¹è¯æ ¸å¿ƒå¼•æ“
æä¾›è‡ªç„¶è¯­è¨€ç†è§£ã€ä¸Šä¸‹æ–‡ç®¡ç†å’Œå¤šè½®å¯¹è¯åŠŸèƒ½
"""
import os
from typing import List, Dict, Optional, Any

# æ˜¾å¼åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("Warning: python-dotenv not installed, using system environment variables only")

from typing import List, Dict, Optional, Any
from typing import Optional
from pydantic import Field
from pydantic_settings import BaseSettings
import logging

logger = logging.getLogger(__name__)


class Settings(BaseSettings):
    """ç³»ç»Ÿé…ç½®ç±»åˆ«"""
    
    # Gemini API
    gemini_api_key: Optional[str] = Field(default=None, env="GEMINI_API_KEY")
    gemini_model: str = Field(default="gemini-2.0-flash-exp", env="GEMINI_MODEL")
    
    # VEO API (è§†é¢‘ç”Ÿæˆ)
    veo_api_key: Optional[str] = Field(default=None, env="VEO_API_KEY")
    
    # System Settings
    max_retry_attempts: int = Field(default=3, env="MAX_RETRY_ATTEMPTS")
    timeout_seconds: int = Field(default=30, env="TIMEOUT_SECONDS")
    
    class Config:
        env_file = ".env"
        case_sensitive = False


# ä½¿ç”¨æ–°ç‰ˆ google.genai API
try:
    from google import genai
    from google.genai import types
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    genai = None

class GeminiEngine:
    """Gemini å¯¹è¯å¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ– Gemini API"""
        if not GENAI_AVAILABLE or genai is None:
            logger.error("âŒ google-genai å¥—ä»¶æœªå®‰è£…ï¼Œå¯¹è¯åŠŸèƒ½ä¸å¯ç”¨")
            logger.info("ğŸ’¡ è¯·æ‰§è¡Œ: pip install google-genai>=1.47.0")
            raise ImportError("google-genai å¥—ä»¶æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œ: pip install google-genai>=1.47.0")
        
        # åˆå§‹åŒ–é…ç½®
        self.settings = Settings()
        
        # è·å–API key - æŒ‰ä¼˜å…ˆçº§ä»å¤šä¸ªæ¥æºè·å–
        api_key = None
        if self.settings.gemini_api_key:
            api_key = self.settings.gemini_api_key
        else:
            # ç›´æ¥ä»ç¯å¢ƒå˜é‡è·å–
            api_key = os.getenv('GEMINI_API_KEY')
        
        if not api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° GEMINI_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡")
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆéšè—API keyï¼‰
        logger.info(f"âœ… æ‰¾åˆ°API Key: {api_key[:8]}...{api_key[-4:]}")
        
        # ä½¿ç”¨æ–°ç‰ˆ API Client
        try:
            self.client = genai.Client(api_key=api_key)
            self.model_name = self.settings.gemini_model
            self.conversation_history: List[Dict[str, str]] = []
            logger.info("âœ… Gemini å¯¹è¯å¼•æ“åˆå§‹åŒ–æˆåŠŸ (ä½¿ç”¨æ–°ç‰ˆ google.genai API)")
        except Exception as e:
            logger.error(f"âŒ Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise ValueError(f"Gemini API åˆå§‹åŒ–å¤±è´¥: {e}")
        
    def chat(self, user_input: str, system_prompt: Optional[str] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›å›åº”
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            åŒ…å«å›åº”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            # æ„å»ºå¯¹è¯å†…å®¹
            contents = []
            
            if system_prompt:
                contents.append(types.Content(
                    role="user",
                    parts=[types.Part(text=system_prompt)]
                ))
                contents.append(types.Content(
                    role="model",
                    parts=[types.Part(text="ç†è§£ï¼Œæˆ‘ä¼šååŠ©æ‚¨å®Œæˆå„ç§åˆ›ä½œä»»åŠ¡ã€‚")]
                ))
            
            # æ·»åŠ å†å²å¯¹è¯
            for msg in self.conversation_history[-10:]:  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
                contents.append(types.Content(
                    role=msg["role"],
                    parts=[types.Part(text=msg["parts"])]
                ))
            
            # æ·»åŠ å½“å‰è¾“å…¥
            contents.append(types.Content(
                role="user",
                parts=[types.Part(text=user_input)]
            ))
            
            # è°ƒç”¨ Gemini API (æ–°ç‰ˆ)
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=contents
            )
            
            # æå–å›åº”
            response_text = response.text
            
            # æ›´æ–°å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "parts": user_input})
            self.conversation_history.append({"role": "model", "parts": response_text})
            
            # å¤„ç† metadata
            metadata = {}
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                try:
                    metadata = {
                        "prompt_token_count": getattr(response.usage_metadata, 'prompt_token_count', 0),
                        "candidates_token_count": getattr(response.usage_metadata, 'candidates_token_count', 0),
                        "total_token_count": getattr(response.usage_metadata, 'total_token_count', 0)
                    }
                except:
                    metadata = {}
            
            return {
                "response": response_text,
                "task_type": self._detect_task_type(user_input, response_text),
                "confidence": self._calculate_confidence(response),
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Gemini API è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _detect_task_type(self, user_input: str, response: str) -> str:
        """
        æ£€æµ‹ä»»åŠ¡ç±»å‹
        
        Returns:
            ä»»åŠ¡ç±»å‹: 'text_gen' | 'image_gen' | 'video_gen' | 'speech2video' | 'multimodal'
        """
        input_lower = user_input.lower()
        response_lower = response.lower()
        
        # å›¾åƒç”Ÿæˆå…³é”®è¯
        if any(word in input_lower for word in ['ç”»', 'ç”Ÿæˆå›¾ç‰‡', 'image', 'å›¾', 'å›¾ç‰‡', 'æ’å›¾']):
            return 'image_gen'
        
        # è§†é¢‘ç”Ÿæˆå…³é”®è¯
        if any(word in input_lower for word in ['è§†é¢‘', 'çŸ­ç‰‡', 'åŠ¨ç”»', 'video', 'å½±ç‰‡']):
            if any(word in input_lower for word in ['è¯­éŸ³', 'å£°éŸ³', 'speech', 'audio', 'é…éŸ³']):
                return 'speech2video'
            elif any(word in input_lower for word in ['å›¾ç‰‡', 'image', 'å›¾']):
                return 'video_gen'
        
        # å¤šæ¨¡æ€ä»»åŠ¡
        if any(word in input_lower for word in ['å®Œæ•´', 'å…¨å¥—', 'æ•´ä½“', 'æµç¨‹']):
            return 'multimodal'
        
        # é»˜è®¤ä¸ºæ–‡æœ¬ç”Ÿæˆ
        return 'text_gen'
    
    def _calculate_confidence(self, response: Any) -> float:
        """
        è®¡ç®—å›åº”çš„ä¿¡å¿ƒåº¦
        
        Returns:
            0.0 åˆ° 1.0 ä¹‹é—´çš„ä¿¡åº¦å€¼
        """
        # åŸºäºå›åº”é•¿åº¦å’Œå†…å®¹è´¨é‡è®¡ç®—ä¿¡åº¦
        text = response.text if hasattr(response, 'text') else ""
        if len(text) < 10:
            return 0.3
        elif len(text) > 100:
            return 0.9
        else:
            return 0.5 + (len(text) / 100) * 0.4
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.conversation_history = []
        logger.info("å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def get_history_summary(self) -> str:
        """è·å–å¯¹è¯å†å²æ‘˜è¦"""
        if not self.conversation_history:
            return "æ²¡æœ‰å¯¹è¯å†å²"
        
        summary = f"å…± {len(self.conversation_history)} è½®å¯¹è¯\n"
        summary += f"æœ€åä¸€è½®: {self.conversation_history[-2]['parts'][:50]}..."
        return summary